# 人工智能02

Classical：用树来进行搜索

Beyond：不用树

如果有数学形式的，就求导，而不是搜索

问题的取值范围是离散的，但是建模可以是连续的，只要精度下降的不那么快

对于数学形式$f({x_1},{x_2}...{x_i})$可导

## 梯度下降

代表沿着最陡峭的地方下降

连续空间中的贪心算法

如果有数学形式，在连续的空间中，求导
$$
x \leftarrow x + \alpha f(x)
$$
当没有梯度时（$f(x)$不可导）

- 人为定义x到x+Δx

- 蒙特卡洛方法

## 怎么找到最优解

### 爬山法

search

1. 怎么产生新的x‘
2. 下一次循环是从x还是从x’开始

这里的爬山法是$x<f(x)$，则用f（x）替换x

梯度属于某种情况的爬山法

- 根据梯度的性质得到
- 就是一种贪心的方法

但是，得到的情况可能是局部最优，而不是全局最优

解决方法：

exploration

- 极致是random search
- 不知道短期回报是否最好，先找到长期回报

exploitation

- 极致是爬山法
- 追求短期回报

### 具体应用

#### 模拟退火（simulated annealing）

```pesdo-code
Do while （halt condition is not satisfied）
• Generate solution x’ based on x(t)
• Evaluate the f (x’)
• If f(x’)>f(xi)，
• Then x(t+1) = x’，otherwise x(t+1) = x
• i=i+1
```

$$
p=\left\{\begin{array}{ccc}{1} & {\text { if }} & {f\left(x_{i}\right)<f\left(x_{i}^{\prime}\right)} \\ {\exp \left(-\frac{f\left(x_{i}\right)-f\left(x_{i}^{\prime}\right)}{T}\right)} & {\text { if }} & {f\left(x_{i}\right) \geq f\left(x_{i}^{\prime}\right)}\end{array}\right.
$$

如果新产生的x‘比x好，就替换

如果新产生的x’不必x好，就不替换

- exp描述的是x比x‘差了多少就替换的比率

- T变小，替换的概率变小

调参方法：经过前若干轮，T进行数值变化

### 竞技搜索（Tabu Search）

对于好的，就改进

要求对于搜索的循环，要求去没去过的地方

```
Do while （halt condition is not satisfied）
• Generate solution x’ based on x(t)
• Evaluate the f (x’)
• If f(x’)>f(xi) and f(x')不等于所有以前的x
• Then x(t+1) = x’，otherwise x(t+1) = x
• i=i+1
```

如果规模很大，实现就很难做到

如果搞一个内存，怎么存储也需要策略

### 遗传算法（Population-based search）

设置多个点，进行爬山法

只要撒的点足够多，就有概率达到最优解

就是并行搜索

#### 演化计算

通过任意一堆点的方向指向，获得方向更准确的估计

不知道梯度的情况下，得到点对的估计

一个一个点走，就是没有

### NCS

希望两个点爬不同的山，走不同的方向

由于是多维度的，方向很难一致

如果方向比较近，夹角趋近于0，就认定两个点在爬同一座山

## 怎么更好的产生x’

- naive 

$$
x^{\prime}=x+\Delta, \Delta \sim N(0,1)
$$

- 贝叶斯优化
  - 在点和点之间建立置信区间，对于这个区间上的每一个点，确定他们的可信度有多大，得到f（x），r（x），通过f（x）和r（x）之间的比较，确定其x‘
- 使用概率分布
  - 使用期望的估计，就是EDA

- 使用启发式的套路
  - 交叉互换

## 方法和算法

如果算法是定义死的，算法

如果流程是活的，有很多的操作空间，就是方法

对于很数学，用包就行了

对于不太数学的东西，就用搜索方法

